{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9967023-6bef-45ee-9998-5d0abf2b4688",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Leveraging Databricks Lakehouse & system table to forecast your billing\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/system_tables/uc-system-tables-flow.png?raw=true\" width=\"800px\" style=\"float: right\">\n",
    "\n",
    "As your billing information is saved in your system table, it's easy to leverage the lakehouse capabilities to forecast your consumption, and add alerts.\n",
    "\n",
    "In this notebook, we'll run some analysis on the current consumption and build a Prophet model to forecast the future usage, based on SKU and workspace.\n",
    "\n",
    "Because each workspace can have a different pattern / trend, we'll specialize multiple models on each SKU and Workspace and train them in parallel.\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=governance&org_id=1444828305810485&notebook=%2F01-billing-tables%2F02-forecast-billing-tables&demo_name=uc-04-system-tables&event=VIEW&path=%2F_dbdemos%2Fgovernance%2Fuc-04-system-tables%2F01-billing-tables%2F02-forecast-billing-tables&version=1&user_hash=ddf348067415027dc6243f8b145629a2bf969356f50e695cd9fcf1cc18a6c40d\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "890823f9-4a29-401a-b41a-71c17132ceca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Note: refresh your forecast data every day\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/system_tables/uc-system-job.png?raw=true\" style=\"float: left; margin: 20px\" width=\"550px\">\n",
    "\n",
    "Make sure you refresh your forecast every day to get accurate previsions. \n",
    "\n",
    "To do that, simply click on Schedule and select \"Every Day\" to create a new Workflow refreshing this notebook on a daily basis. \n",
    "\n",
    "If you don't do it, your forecast will quickly expire and won't reflect potential consumption change / trigger alerts.\n",
    "\n",
    "To make sure this happens, we also added a tracker in the Databricks SQL dashboard to display the number of days since the last forecast. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf86edf0-ca12-4fe5-b2b1-c3a377b8407a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A note on pricing tables\n",
    "Note that Pricing tables (containing the price information in `$` for each SKU) is available as a system table.\n",
    "\n",
    "**Please consider these numbers as estimates which do not include any add-ons or discounts. It is using list price, not contractual. Please review your contract for more accurate information.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e73cc4da-c592-400f-bbd1-a4efee3b31b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Granular Forecasts\n",
    "\n",
    "SKUs are detailed per line of product and per region. To simplify our billing dashboard, we'll merge them under common SKU types i.e. grouping `STANDARD_ALL_PURPOSE_COMPUTE` and `PREMIUM_ALL_PURPOSE_COMPUTE` as `ALL_PURPOSE`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fd294ab-3f97-43f5-a894-73d5e4124939",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Leveraging Databricks AI_FORECAST function\n",
    "\n",
    "Databricks provides a built-in AI Forecast capability. See the [AI_FORECAST documentation](https://docs.databricks.com/en/sql/language-manual/functions/ai_forecast.html) for more details.\n",
    "\n",
    "**Note that this might require the preview to be enabled to your workspace. If the preview isn't enable, we show you how to do the forecast below using prophet in python.**\n",
    "\n",
    "**Make sure you run these next cells using a SQL WAREHOUSE as compute, not a classic cluster as the AI_FORECAST preview is only available in serverless for now.**\n",
    "\n",
    "*Note: If the `AI_FORECAST` isn't yet available in your workspace, you can skip to the next section where we show you how to do the same in python.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98080c1a-dc87-41e7-a9c2-5590a661e7e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- NOTE: make sure you run this notebook using a SQL Warehouse or Serverless endpoint (not a classic cluster).\n",
    "SELECT assert_true(current_version().dbsql_version is not null, 'YOU MUST USE A SQL WAREHOUSE TO RUN THE NEXT CELLS HAVING THE AI_FORECAST FUNCTION, not a classic cluster');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c214ce4e-d00c-4cfa-ac52-1d12fc85b150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from system.billing.usage u\n",
    "  inner join system.billing.list_prices lp on u.cloud = lp.cloud and\n",
    "    u.sku_name = lp.sku_name and\n",
    "    u.usage_start_time >= lp.price_start_time and\n",
    "    (u.usage_end_time <= lp.price_end_time or lp.price_end_time is null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4a73d15-fb40-4acc-966e-d94811fdbea6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create the view, grouping by type of DBUs"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW data_to_predict AS (\n",
    "WITH \n",
    "-- Classify SKU types and calculate usage metrics\n",
    "classified_data AS (\n",
    "    SELECT \n",
    "        u.workspace_id, \n",
    "        u.usage_date AS ds, \n",
    "        CASE\n",
    "            WHEN u.sku_name LIKE '%ALL_PURPOSE%' THEN 'ALL_PURPOSE'\n",
    "            WHEN u.sku_name LIKE '%JOBS%' THEN 'JOBS'\n",
    "            WHEN u.sku_name LIKE '%DLT%' THEN 'DLT'\n",
    "            WHEN u.sku_name LIKE '%SQL%' THEN 'SQL'\n",
    "            WHEN u.sku_name LIKE '%INFERENCE%' THEN 'MODEL_INFERENCE'\n",
    "            ELSE 'OTHER'\n",
    "        END AS sku,\n",
    "        CAST(u.usage_quantity AS DOUBLE) AS dbus, \n",
    "        CAST(lp.pricing.default * u.usage_quantity AS DOUBLE) AS cost_at_list_price\n",
    "    FROM \n",
    "        system.billing.usage u\n",
    "    INNER JOIN \n",
    "        system.billing.list_prices lp \n",
    "    ON \n",
    "        u.cloud = lp.cloud \n",
    "        AND u.sku_name = lp.sku_name \n",
    "        AND u.usage_start_time >= lp.price_start_time \n",
    "        AND (u.usage_end_time <= lp.price_end_time OR lp.price_end_time IS NULL)\n",
    "    WHERE \n",
    "        u.usage_unit = 'DBU'\n",
    "),\n",
    "-- Aggregate data by day, SKU, and workspace\n",
    "daily_data AS (\n",
    "    SELECT \n",
    "        ds,\n",
    "        sku,\n",
    "        workspace_id,\n",
    "        SUM(dbus) AS dbus,\n",
    "        SUM(cost_at_list_price) AS cost_at_list_price\n",
    "    FROM \n",
    "        classified_data\n",
    "    GROUP BY \n",
    "        ds, sku, workspace_id\n",
    "),\n",
    "-- Generate totals: workspace, SKU, and global\n",
    "workspace_totals AS (\n",
    "    SELECT ds, 'ALL' AS sku, workspace_id, SUM(dbus) AS dbus, SUM(cost_at_list_price) AS cost_at_list_price\n",
    "    FROM daily_data\n",
    "    GROUP BY ds, workspace_id\n",
    "),\n",
    "sku_totals AS (\n",
    "    SELECT ds, sku, 'ALL' AS workspace_id, SUM(dbus) AS dbus, SUM(cost_at_list_price) AS cost_at_list_price\n",
    "    FROM daily_data\n",
    "    GROUP BY ds, sku\n",
    "),\n",
    "global_totals AS (\n",
    "    SELECT ds, 'ALL' AS sku, 'ALL' AS workspace_id, SUM(dbus) AS dbus, SUM(cost_at_list_price) AS cost_at_list_price\n",
    "    FROM daily_data\n",
    "    GROUP BY ds\n",
    "),\n",
    "-- Filter for active workspaces\n",
    "active_workspaces AS (\n",
    "    SELECT DISTINCT workspace_id\n",
    "    FROM daily_data\n",
    "    WHERE ds >= CURRENT_DATE - INTERVAL 7 DAYS\n",
    "),\n",
    "-- Combine all data into a single dataset\n",
    "combined_data AS (\n",
    "    SELECT * FROM daily_data WHERE workspace_id IN (SELECT workspace_id FROM active_workspaces)\n",
    "    UNION ALL\n",
    "    SELECT * FROM workspace_totals WHERE workspace_id IN (SELECT workspace_id FROM active_workspaces)\n",
    "    UNION ALL\n",
    "    SELECT * FROM sku_totals\n",
    "    UNION ALL\n",
    "    SELECT * FROM global_totals\n",
    ")\n",
    "-- Add the MAX computation after the UNION (we use it as cap in our forecast)\n",
    "SELECT \n",
    "    *,\n",
    "    MAX(cost_at_list_price) OVER (PARTITION BY sku, workspace_id) AS max_cost_at_list_price\n",
    "FROM combined_data\n",
    ");\n",
    "\n",
    "SELECT * FROM data_to_predict ORDER BY sku, workspace_id, ds limit 1000 ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6396aa70-451b-4428-9505-7d7ba1e832cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's now leverage the `AI_FORECAST` function to forecast the future pricing fur each sku/workspace id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb760e55-c3fb-4af8-8607-4cd6d303e354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS mozuca.main.billing_forecast;\n",
    "CREATE TABLE mozuca.main.billing_forecast AS \n",
    "WITH data_to_predict_with_params AS (\n",
    "  SELECT \n",
    "    '{\"global_floor\": 0, \"min_changepoint_samples\": 30, \"global_cap\": ' || (max_cost_at_list_price * 5) || '}' AS parameters,\n",
    "    ds, \n",
    "    cost_at_list_price, \n",
    "    sku, \n",
    "    workspace_id\n",
    "  FROM data_to_predict\n",
    ")\n",
    "SELECT \n",
    "  *, \n",
    "  current_date() as training_date\n",
    "FROM ai_forecast(\n",
    "  TABLE(data_to_predict_with_params),\n",
    "  horizon => (SELECT MAX(ds) + INTERVAL 120 DAYS FROM data_to_predict),\n",
    "  time_col => 'ds',\n",
    "  value_col => 'cost_at_list_price',\n",
    "  prediction_interval_width => 0.8,\n",
    "  frequency => 'D',\n",
    "  group_col => ARRAY('sku', 'workspace_id'),\n",
    "  parameters => 'parameters'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c967e13-1241-43dd-b02c-a2d670d03ee8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Our forecast are ready!"
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "select * from mozuca.main.billing_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8038aed8-afb4-4dfc-9ec8-04a2b893fd04",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Merge forecast data and history in a single table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS mozuca.main.detailed_billing_forecast;\n",
    "CREATE OR REPLACE TABLE mozuca.main.detailed_billing_forecast AS \n",
    "  WITH forecast_data as (\n",
    "    SELECT \n",
    "      NULL as training_date, \n",
    "      ds, \n",
    "      sku, \n",
    "      workspace_id, \n",
    "      cost_at_list_price as past_list_cost, \n",
    "      NULL as cost_at_list_price_forecast, \n",
    "      NULL as cost_at_list_price_upper, \n",
    "      NULL as cost_at_list_price_lower \n",
    "      FROM data_to_predict \n",
    "        UNION \n",
    "    SELECT \n",
    "      training_date,\n",
    "      ds, \n",
    "      sku, \n",
    "      workspace_id, \n",
    "      NULL as past_list_cost, \n",
    "      GREATEST(0, cost_at_list_price_forecast), \n",
    "      GREATEST(0, cost_at_list_price_upper), \n",
    "      GREATEST(0, cost_at_list_price_lower) \n",
    "      FROM  mozuca.main.billing_forecast)\n",
    "\n",
    "    SELECT * EXCEPT(ds), \n",
    "      ds as date,\n",
    "      past_list_cost is null as is_prediction,\n",
    "      coalesce(past_list_cost, cost_at_list_price_forecast) as list_cost,\n",
    "      avg(coalesce(past_list_cost, cost_at_list_price_forecast)) OVER (PARTITION BY sku, workspace_id ORDER BY ds ROWS BETWEEN 7 PRECEDING AND 7 FOLLOWING) AS list_cost_ma,\n",
    "      avg(cost_at_list_price_forecast) OVER (PARTITION BY sku, workspace_id ORDER BY ds ROWS BETWEEN 7 PRECEDING AND 7 FOLLOWING) AS forecast_list_cost_ma, \n",
    "      avg(cost_at_list_price_lower) OVER (PARTITION BY sku, workspace_id ORDER BY ds ROWS BETWEEN 7 PRECEDING AND 7 FOLLOWING) AS forecast_list_cost_lower_ma,\n",
    "      avg(cost_at_list_price_upper) OVER (PARTITION BY sku, workspace_id ORDER BY ds ROWS BETWEEN 7 PRECEDING AND 7 FOLLOWING) AS forecast_list_cost_upper_ma\n",
    "    from forecast_data\n",
    "    ORDER BY sku, workspace_id, ds;\n",
    "\n",
    "SELECT * FROM mozuca.main.detailed_billing_forecast order by date desc limit 1000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23adfc90-2fa0-4644-b437-20e94eaa0cc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from mozuca.main.billing_forecast order by ds desc limit 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6d9cdff-4c9e-42f4-aa00-7c87d9742d92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Manual AI Forecast leveraging Prophet and pandas UDF with spark\n",
    "\n",
    "If the AI_FORECAST function isn't available yet in your workspace, you can do the prediction manually in python with prophet.\n",
    "\n",
    "**Note: if you already ran the AI_FORECAST function, you can skip these next steps** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3f07c0d-5dce-49e5-bc3b-7dec12e331d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install prophet==1.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebbb0ba2-7c71-4531-8025-5ccbe50a97a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecff89f3-05e5-4f5a-9ddd-146cc29177f0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Group by main SKU category"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, sum, current_date, lit\n",
    "data_to_predict = spark.sql(\"\"\"\n",
    "  select u.workspace_id, \n",
    "  u.usage_date as ds, \n",
    "  u.sku_name as sku, \n",
    "  cast(u.usage_quantity as double) as dbus, \n",
    "  cast(lp.pricing.default*usage_quantity as double) as cost_at_list_price \n",
    "  \n",
    "  from system.billing.usage u \n",
    "      inner join system.billing.list_prices lp on u.cloud = lp.cloud and\n",
    "        u.sku_name = lp.sku_name and\n",
    "        u.usage_start_time >= lp.price_start_time and\n",
    "        (u.usage_end_time <= lp.price_end_time or lp.price_end_time is null)\n",
    "  where u.usage_unit = 'DBU'\n",
    "\"\"\")\n",
    "\n",
    "#Group the SKU in main family that we'll predict\n",
    "data_to_predict = data_to_predict.withColumn(\"sku\",\n",
    "                     when(col(\"sku\").contains(\"ALL_PURPOSE\"), \"ALL_PURPOSE\")\n",
    "                    .when(col(\"sku\").contains(\"JOBS\"), \"JOBS\")\n",
    "                    .when(col(\"sku\").contains(\"DLT\"), \"DLT\")\n",
    "                    .when(col(\"sku\").contains(\"SQL\"), \"SQL\")\n",
    "                    .when(col(\"sku\").contains(\"INFERENCE\"), \"MODEL_INFERENCE\")\n",
    "                    .otherwise(\"OTHER\"))\n",
    "                  \n",
    "# Sum the consumption at a daily level (1 value per day and per sku+workspace)\n",
    "data_to_predict_daily = data_to_predict.groupBy(col(\"ds\"), col('sku'), col('workspace_id')).agg(sum('dbus').alias(\"dbus\"), sum('cost_at_list_price').alias(\"cost_at_list_price\"))\n",
    "\n",
    "display(data_to_predict_daily)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d010c8c-d530-4fb2-9bb3-40a995efe07d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Using prophet to forecast our billing data\n",
    "\n",
    "Once aggregated at a daily level, billing information can be forecasted as a timeseries. For this demo, we will use a simple Prophet model to extend the timeseries to the next quarter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de6ffd0d-3282-4602-9deb-88355405904e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "#Predict days, for the next 3 months\n",
    "forecast_frequency='d'\n",
    "forecast_periods=31*3\n",
    "\n",
    "interval_width=0.8\n",
    "include_history=True\n",
    "\n",
    "def generate_forecast(history_pd, display_graph = True):\n",
    "    # remove any missing values\n",
    "    history_pd = history_pd.dropna()\n",
    "    if history_pd.shape[0] > 10:\n",
    "        # train and configure the model\n",
    "        model = Prophet(interval_width=interval_width )\n",
    "        model.add_country_holidays(country_name='US')\n",
    "\n",
    "        model.fit(history_pd)\n",
    "\n",
    "        # make predictions\n",
    "        future_pd = model.make_future_dataframe(periods=forecast_periods, freq=forecast_frequency, include_history=include_history)\n",
    "        future_pd['floor'] = 0  # Set the floor for future predictions\n",
    "        forecast_pd = model.predict(future_pd)\n",
    "\n",
    "        if display_graph:\n",
    "           model.plot(forecast_pd)\n",
    "        # add back y to the history dataset \n",
    "        f_pd = forecast_pd[['ds', 'yhat', 'yhat_upper', 'yhat_lower']].set_index('ds')\n",
    "        # join history and forecast\n",
    "        results_pd = f_pd.join(history_pd[['ds','y','dbus']].set_index('ds'), how='left')\n",
    "        results_pd.reset_index(level=0, inplace=True)\n",
    "        results_pd['ds'] = results_pd['ds'].dt.date\n",
    "        # get sku & workspace id from incoming data set\n",
    "        results_pd['sku'] = history_pd['sku'].iloc[0]\n",
    "        results_pd['workspace_id'] = history_pd['workspace_id'].iloc[0]\n",
    "    else:\n",
    "        # not enough data to predict, return history\n",
    "        for c in ['yhat', 'yhat_upper', 'yhat_lower']:\n",
    "            history_pd[c] = history_pd['y']\n",
    "        results_pd = history_pd[['ds','y','dbus','yhat', 'yhat_upper', 'yhat_lower', 'sku', 'workspace_id']]\n",
    "    return results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31cf6533-7b5d-4003-b120-89547004d547",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS billing_forecast_manual;\n",
    "-- create the billing forecast table:\n",
    "CREATE TABLE IF NOT EXISTS billing_forecast_manual (ds DATE, yhat DOUBLE, yhat_upper DOUBLE, yhat_lower DOUBLE, y DOUBLE, dbus DOUBLE, sku STRING, workspace_id STRING, training_date DATE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa95df15-fcb9-4521-b989-1936e99efce4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Forecast for the sum of all DBUS"
    }
   },
   "outputs": [],
   "source": [
    "#Sum all the SKUs & Workspace for global consumption trend (by default we want a view for all our billing usage across all workspace, so we need to train a specific model on that too)\n",
    "global_forecast = data_to_predict_daily.groupBy(col(\"ds\")).agg(sum('cost_at_list_price').alias(\"y\"), sum('dbus').alias(\"dbus\")) \\\n",
    "                                       .withColumn('sku', lit('ALL')) \\\n",
    "                                       .withColumn('workspace_id', lit('ALL')).toPandas()\n",
    "global_forecast = generate_forecast(global_forecast)\n",
    "spark.createDataFrame(global_forecast).withColumn('training_date', current_date()) \\\n",
    "                                      .write.mode('overwrite').option(\"mergeSchema\", \"true\").saveAsTable(\"billing_forecast_manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9240281c-da34-46f5-bca9-fe570f1dbff1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Distribute training for each DBU SKUs to have specialized models & predictions"
    }
   },
   "outputs": [],
   "source": [
    "def generate_forecast_udf(history_pd):\n",
    "  return generate_forecast(history_pd, False)\n",
    "\n",
    "#Add an entry with the sum of all types of DBU per workspace\n",
    "all_per_workspace = data_to_predict_daily.groupBy('ds', 'workspace_id').agg(sum('cost_at_list_price').alias(\"cost_at_list_price\"), sum('dbus').alias(\"dbus\")) \\\n",
    "                                         .withColumn('sku', lit('ALL'))\n",
    "all_skus = data_to_predict_daily.groupBy('ds', 'sku').agg(sum('cost_at_list_price').alias(\"cost_at_list_price\"), sum('dbus').alias(\"dbus\")) \\\n",
    "                                         .withColumn('workspace_id', lit('ALL'))\n",
    "\n",
    "results = (\n",
    "  data_to_predict_daily\n",
    "    .union(all_per_workspace.select(data_to_predict_daily.columns)) #Add all workspaces for all skus\n",
    "    .union(all_skus.select(data_to_predict_daily.columns)) #Add all sku across all workspaces\n",
    "    .withColumnRenamed('cost_at_list_price', 'y') #Prophet expect 'y' as input to predict\n",
    "    .groupBy('workspace_id', 'sku') # Group by SKU + Workspace and call our model for each group\n",
    "    .applyInPandas(generate_forecast_udf, schema=\"ds date, yhat double, yhat_upper double, yhat_lower double, y double, dbus double, sku string, workspace_id string\")\n",
    "    .withColumn('training_date', current_date()))\n",
    "\n",
    "#Save back to tables to our final table that we'll be using in our dashboard\n",
    "results.write.mode('append').saveAsTable(\"billing_forecast_manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6af137f9-7229-4d3d-87c3-90f2775ceb48",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Our forecasting data is ready"
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "select * from billing_forecast_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93be238f-df4a-4042-b32b-8a0773f51c75",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create a view on top to simplify access"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace view detailed_billing_forecast_manual as \n",
    "with forecasts as (\n",
    "  select\n",
    "    f.ds as date,\n",
    "    f.workspace_id,\n",
    "    f.sku,\n",
    "    f.y,\n",
    "    GREATEST(0, f.yhat) as yhat,\n",
    "    GREATEST(0, f.yhat_lower) as yhat_lower,\n",
    "    GREATEST(0, f.yhat_upper) as yhat_upper,\n",
    "    f.training_date\n",
    "  from mozuca.main.billing_forecast_manual f\n",
    ")\n",
    "select\n",
    "  `date`,\n",
    "  workspace_id,\n",
    "  sku,\n",
    "  y as past_list_cost, -- real\n",
    "  y is null as is_prediction ,\n",
    "  coalesce(y, yhat) as list_cost, -- contains real and forecast\n",
    "  yhat as cost_at_list_price_forecast,  -- forecast\n",
    "  yhat_lower as cost_at_list_price_lower,\n",
    "  yhat_upper as cost_at_list_price_upper,\n",
    "  -- smooth upper and lower bands for better visualization\n",
    "  avg(yhat) OVER (PARTITION BY sku, workspace_id ORDER BY date ROWS BETWEEN 7 PRECEDING AND 7 FOLLOWING) AS forecast_list_cost_ma, \n",
    "  avg(yhat_lower) OVER (PARTITION BY sku, workspace_id ORDER BY date ROWS BETWEEN 7 PRECEDING AND 7 FOLLOWING) AS forecast_list_cost_upper_ma,\n",
    "  avg(yhat_upper) OVER (PARTITION BY sku, workspace_id ORDER BY date ROWS BETWEEN 7 PRECEDING AND 7 FOLLOWING) AS forecast_list_cost_lower_ma,\n",
    "  training_date\n",
    "from\n",
    "  forecasts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df89dbd0-4d6d-474c-a028-4cc26c43681d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "select * from detailed_billing_forecast_manual  where sku = 'ALL' limit 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cb49d7a-1eb4-4c67-bedf-8f8b1a7e86ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Your forecast tables are ready for BI\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/uc/system_tables/dashboard-governance-billing.png?raw=true\" width=\"500px\" style=\"float: right\">\n",
    "\n",
    "dbdemos installed a dashboard for you to start exploring your data. \n",
    "<a dbdemos-dashboard-id=\"account-usage\" href='/sql/dashboardsv3/01f04ac4dd2916d090bae9c2e8a2f168'>Open the dashboard</a> to start exploring your billing data.<br/>\n",
    "Remember that if you changed your Catalog and Schema, you'll have to update the queries.\n",
    "\n",
    "\n",
    "## Exploring our forecasting data from the notebook\n",
    "\n",
    "Our forecasting data is ready! We can explore it within the notebook directly, using Databricks built-in widget our any python plot library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f17874c1-c0fa-4791-abe7-c8405ebb2180",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Forecast consumption for all SKU in all our workspaces"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "df = spark.table('detailed_billing_forecast_manual').where(\"sku = 'ALL' and workspace_id='ALL'\").toPandas()\n",
    "#Remove the last point as the day isn't completed (not relevant)\n",
    "df.at[df['past_list_cost'].last_valid_index(), 'past_list_cost'] = None\n",
    "\n",
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['date'], y=df['past_list_cost'][:-4], name='actual usage'))\n",
    "fig.add_trace(go.Scatter(x=df['date'], y=df['cost_at_list_price_forecast'], name='forecast cost (pricing list)'))\n",
    "fig.add_trace(go.Scatter(x=df['date'], y=df['cost_at_list_price_upper'], name='forecast cost up', line = dict(color='grey', width=1, dash='dot')))\n",
    "fig.add_trace(go.Scatter(x=df['date'], y=df['cost_at_list_price_lower'], name='forecast cost low', line = dict(color='grey', width=1, dash='dot')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca2c1410-c5b3-4d4a-99c7-91abbd69f4dc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Detailed view for each SKU"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from pyspark.sql.functions import date_sub\n",
    "\n",
    "one_year_ago = date_sub(current_date(), 365)\n",
    "df = spark.table('detailed_billing_forecast_manual').where(\"workspace_id='ALL'\").where(col('date') >= one_year_ago).groupBy('sku', 'date').agg(sum('list_cost').alias('list_cost')).orderBy('date').toPandas()\n",
    "px.line(df, x=\"date\", y=\"list_cost\", color='sku')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e740471-e5c5-4a75-90d4-00866f253331",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Top 5 workspaces view"
    }
   },
   "outputs": [],
   "source": [
    "#Focus on the ALL PURPOSE dbu\n",
    "df = spark.table('detailed_billing_forecast_manual').where(\"sku = 'ALL_PURPOSE' and workspace_id != 'ALL'\")\n",
    "#Get the top 5 worpskaces consuming the most\n",
    "top_workspace = df.groupBy('workspace_id').agg(sum('list_cost').alias('list_cost')).orderBy(col('list_cost').desc()).limit(5)\n",
    "workspace_id = [r['workspace_id'] for r in top_workspace.collect()]\n",
    "#Group consumption per workspace\n",
    "df = df.where(col('workspace_id').isin(workspace_id)).groupBy('workspace_id', 'date').agg(sum('list_cost').alias('list_cost')).orderBy('date').toPandas()\n",
    "px.bar(df, x=\"date\", y=\"list_cost\", color=\"workspace_id\", title=\"Long-Form Input\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02-forecast-billing-tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
